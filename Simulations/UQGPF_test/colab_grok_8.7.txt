# نسخه ۸٫۷: کد MCMC بهبودیافته برای فیت UQGPF با داده‌های ACT+SPT و Pantheon+SH0ES
# سازگار با Google Colab: درخواست آپلود فایل‌ها، unzip خودکار، جستجوی recursive، و خواندن سفارشی cov.dat برای مدیریت فرمت‌های نامنظم (حذف | و خطوط نامعتبر)
# رفع خطا: TypeError در np.isnan با افزودن header=0 به pd.read_csv برای خواندن هدر، تبدیل ستون‌ها به numeric با pd.to_numeric (errors='coerce')، و فیلتر valid_mask بر اساس مقادیر مثبت MU_SH0ES
# بهبود مدل SNIa: استفاده از فرم دقیق‌تر برای distance modulus در مدل تخت ΛCDM-like (با ادغام عددی ساده برای luminosity distance)
# فیلتر اضافی: حذف ردیف‌های با MU_SH0ES <= 0 یا NaN

# نصب پیش‌نیازها
!pip install emcee corner
!pip install emcee corner numpy matplotlib scipy
from google.colab import files
import numpy as np
import emcee
import corner
import matplotlib.pyplot as plt
from scipy.linalg import cholesky, solve_triangular
from scipy.integrate import quad
import pandas as pd
import zipfile
import os
import glob

# درخواست آپلود فایل‌ها
print("لطفاً فایل‌های زیر را آپلود کنید:")
print("1. actlite_3yr_v2p2.zip")
print("2. Reference.zip")
uploaded = files.upload()  # کاربر فایل‌ها را آپلود می‌کند

# بررسی فایل‌های آپلودشده
if 'actlite_3yr_v2p2.zip' not in uploaded or 'Reference.zip' not in uploaded:
    raise FileNotFoundError("یکی از فایل‌های مورد نیاز آپلود نشده است. لطفاً دوباره امتحان کنید.")

# unzip فایل‌ها
extract_dir_act = 'actlite_3yr_v2p2_extract'
extract_dir_ref = 'reference_extract'

if not os.path.exists(extract_dir_act):
    with zipfile.ZipFile('actlite_3yr_v2p2.zip', 'r') as zip_ref:
        zip_ref.extractall(extract_dir_act)
    print(f"فایل actlite_3yr_v2p2.zip با موفقیت استخراج شد به {extract_dir_act}")

if not os.path.exists(extract_dir_ref):
    with zipfile.ZipFile('Reference.zip', 'r') as zip_ref:
        zip_ref.extractall(extract_dir_ref)
    print(f"فایل Reference.zip با موفقیت استخراج شد به {extract_dir_ref}")

# جستجوی recursive برای فایل‌های داده ACT+SPT
cl_files = glob.glob(os.path.join(extract_dir_act, '**', 'ACT+SPT_cl.dat'), recursive=True)
cov_files = glob.glob(os.path.join(extract_dir_act, '**', 'ACT+SPT_cov.dat'), recursive=True)

if not cl_files or not cov_files:
    raise FileNotFoundError("فایل‌های ACT+SPT_cl.dat یا ACT+SPT_cov.dat پیدا نشدند. ساختار فولدر را چک کنید.")
cl_path = cl_files[0]
cov_path = cov_files[0]
print(f"مسیر cl.dat یافت‌شده: {cl_path}")
print(f"مسیر cov.dat یافت‌شده: {cov_path}")

# جستجوی recursive برای فایل SNIa از Reference.zip
snia_files = glob.glob(os.path.join(extract_dir_ref, '**', 'ES_AND_COVARPantheon%2BSH0ES.dat.txt'), recursive=True)
if not snia_files:
    raise FileNotFoundError("فایل SNIa پیدا نشد. ساختار فولدر Reference را چک کنید.")
snia_path = snia_files[0]
print(f"فایل SNIa یافت‌شده: {snia_path}")

# تابع خواندن سفارشی برای cov.dat (مدیریت فرمت نامنظم، حذف | و خطوط نامعتبر)
def load_cov_custom(cov_path):
    cov_list = []
    with open(cov_path, 'r') as f:
        for line in f:
            # حذف | و --- و فضاهای اضافی
            cleaned = line.replace('|', '').replace('---', '').strip()
            if cleaned:  # اگر خط خالی نبود
                parts = cleaned.split()  # split بر اساس فضا
                try:
                    row = [float(p) for p in parts if p]  # تبدیل به float و نادیده گرفتن خالی‌ها
                    if len(row) > 0:  # فقط ردیف‌های معتبر
                        cov_list.extend(row)  # اضافه کردن به لیست flat
                except ValueError:
                    continue  # نادیده گرفتن خطوط نامعتبر
    cov_flat = np.array(cov_list)
    n = 89  # تعداد binها (بر اساس داده‌ها)
    expected_size = n * n
    if len(cov_flat) != expected_size:
        raise ValueError(f"اندازه cov_flat نادرست: {len(cov_flat)} != {expected_size}. فایل cov.dat را چک کنید.")
    cov = np.reshape(cov_flat, (n, n))
    cov = (cov + cov.T) / 2  # symmetric کردن
    # بررسی positive-definite و تصحیح کوچک اگر لازم
    try:
        chol_cov = cholesky(cov, lower=True)
    except np.linalg.LinAlgError:
        cov += np.eye(n) * np.abs(np.min(np.diag(cov))) * 1e-6
        chol_cov = cholesky(cov, lower=True)
    inv_cov = solve_triangular(chol_cov, np.eye(n), lower=True).T @ solve_triangular(chol_cov, np.eye(n), lower=True)
    return inv_cov, cov

# بارگذاری داده‌های ACT+SPT (cl.dat استاندارد، cov.dat سفارشی)
def load_act_spt_data(cl_path, cov_path):
    cl_data = np.loadtxt(cl_path)
    ell = cl_data[:, 0]
    cl_tt = cl_data[:, 1]
    cl_err = cl_data[:, 2]
    inv_cov, _ = load_cov_custom(cov_path)
    return ell, cl_tt, inv_cov, cl_err

# بارگذاری داده‌های SNIa (با header=0، تبدیل به numeric، و فیلتر valid)
def load_snia_data(snia_path):
    if not os.path.exists(snia_path):
        raise FileNotFoundError(f"فایل {snia_path} پیدا نشد.")
    snia_df = pd.read_csv(snia_path, sep='\s+', header=0, on_bad_lines='skip')
    # تبدیل ستون‌ها به numeric (تبدیل مقادیر نامعتبر به NaN)
    snia_df['zHD'] = pd.to_numeric(snia_df['zHD'], errors='coerce')
    snia_df['MU_SH0ES'] = pd.to_numeric(snia_df['MU_SH0ES'], errors='coerce')
    snia_df['MU_SH0ES_ERR_DIAG'] = pd.to_numeric(snia_df['MU_SH0ES_ERR_DIAG'], errors='coerce')
    # فیلتر: فقط ردیف‌های معتبر با MU_SH0ES > 0
    valid_mask = (snia_df['MU_SH0ES'] > 0) & snia_df['zHD'].notna() & snia_df['MU_SH0ES'].notna() & snia_df['MU_SH0ES_ERR_DIAG'].notna()
    z = snia_df.loc[valid_mask, 'zHD'].values
    mu = snia_df.loc[valid_mask, 'MU_SH0ES'].values
    mu_err = snia_df.loc[valid_mask, 'MU_SH0ES_ERR_DIAG'].values
    if len(z) == 0:
        raise ValueError("هیچ داده معتبر SNIa پیدا نشد. فایل را چک کنید.")
    return z, mu, mu_err

# مدل UQGPF ساده‌شده برای Cl (با پارامترهای \Omega_m, h, \beta, \gamma, \alpha)
def model_uqgpf(ell, theta):
    Omega_m, h, beta, gamma, alpha = theta
    cl_model = (Omega_m * ell**beta + h * ell**gamma) * alpha  # مدل نمونه (برای دقت بیشتر با CAMB ادغام شود)
    return cl_model

# تابع log-likelihood برای CMB
def log_likelihood_cmb(theta, ell, data, inv_cov):
    model = model_uqgpf(ell, theta)
    residual = data - model
    chi2 = residual @ inv_cov @ residual
    return -0.5 * chi2

# تابع محاسبه luminosity distance در مدل تخت (برای SNIa)
def luminosity_distance(z, Omega_m, h):
    def integrand(x):
        return 1 / np.sqrt(Omega_m * (1 + x)**3 + (1 - Omega_m))
    dl = (3e5 / h) * (1 + z) * quad(integrand, 0, z)[0]
    return dl

# تابع log-likelihood برای SNIa (با محاسبه دقیق‌تر mu)
def log_likelihood_snia(theta, z, mu_data, mu_err):
    Omega_m, h, *_ = theta
    mu_model = np.array([5 * np.log10(luminosity_distance(zi, Omega_m, h)) + 25 for zi in z])
    chi2 = np.sum(((mu_data - mu_model) / mu_err)**2)
    return -0.5 * chi2

# تابع log-posterior کامل
def log_posterior(theta, ell, cl_data, inv_cov, z, mu_data, mu_err):
    if not all(0 < t < 2 for t in theta):  # priors ساده
        return -np.inf
    mean_prior = np.array([0.3, 0.7, 1.0, 0.5, 1.0])
    sigma_prior = np.array([0.1, 0.1, 0.5, 0.5, 0.5])
    priors = np.sum(((theta - mean_prior) ** 2) / (sigma_prior ** 2))
    return log_likelihood_cmb(theta, ell, cl_data, inv_cov) + log_likelihood_snia(theta, z, mu_data, mu_err) - 0.5 * priors

# اجرای MCMC
ell, cl_tt, inv_cov, cl_err = load_act_spt_data(cl_path, cov_path)
z, mu, mu_err = load_snia_data(snia_path)

ndim = 5
nwalkers = 32
nsteps = 25000
p0 = np.random.rand(nwalkers, ndim) * 0.1 + [0.3, 0.7, 1.0, 0.5, 1.0]

sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior, args=(ell, cl_tt, inv_cov, z, mu, mu_err))
sampler.run_mcmc(p0, nsteps, progress=True)

# تحلیل posterior
samples = sampler.get_chain(discard=5000, thin=10, flat=True)
fig = corner.corner(samples, labels=[r"$\Omega_m$", r"$h$", r"$\beta$", r"$\gamma$", r"$\alpha$"])
fig.savefig('uqgpf_posteriors_v8_7.pdf')

# محاسبه chi2 نهایی و residuals
theta_med = np.median(samples, axis=0)
cl_model = model_uqgpf(ell, theta_med)
residuals = (cl_tt - cl_model) / cl_err
print(f"Mean residuals: {np.mean(residuals)}, Std: {np.std(residuals)}")
np.savetxt('residuals_v8_7.csv', residuals, delimiter=',')

# تولید جدول LaTeX
params_df = pd.DataFrame({'Parameter': [r"$\Omega_m$", r"$h$", r"$\beta$", r"$\gamma$", r"$\alpha$"],
                          'Mean': np.mean(samples, axis=0),
                          'Std': np.std(samples, axis=0)})
params_df.to_latex('latex_table_v8_7.tex', index=False, escape=False)

# پلات فیت
plt.errorbar(ell, cl_tt, yerr=cl_err, label='Data', fmt='o', ms=3)
plt.plot(ell, cl_model, label='UQGPF Fit', linewidth=2)
plt.xlabel('ell')
plt.ylabel('Cl TT')
plt.legend()
plt.savefig('uqgpf_fit_v8_7.pdf')
plt.show()