# UQGPF v2.0 MCMC Fitting Code (Version 9.0 - Stabilized Covariance Inversion and Further Widened Priors)
# Changes from v8.8:
# - Always use np.linalg.pinv for cov_inv to handle potentially ill-conditioned covariance matrix (avoids huge chi2 values due to numerical instability).
# - Added computation and print of covariance matrix condition number for diagnostics.
# - Further widened priors for Omega_m (0.05-0.5) and gamma (0.1-0.4) to allow broader exploration, as posteriors were still hitting edges.
# - Increased nwalkers to 48 and nsteps to 15000 for improved sampling and convergence.
# - Minor: Added additional safety checks in model_mu to prevent extrapolation NaNs; clip interpolated values to positive.
# - Note: Based on the provided corner plot (image.png), the posteriors for Omega_m and gamma are at the prior boundaries, indicating the model is pushing towards lower Omega_m and higher gamma to reduce the power at high ell. The extremely high chi2 in v8.8 was likely due to numerical issues with cov_inv; pinv should stabilize this. If chi2 remains high, the model form may need theoretical refinement (e.g., adjusting the damping term or adding a base spectrum).

# Step 1: Install required packages
!pip install emcee
!pip install corner

import numpy as np
import emcee
import corner
import matplotlib.pyplot as plt
import zipfile
import os
import pandas as pd
import re  # For regex parsing
import warnings  # For suppressing warnings
from google.colab import files  # For file upload in Colab (comment out if not in Colab)
from scipy.integrate import cumulative_trapezoid
from scipy.interpolate import interp1d

# Suppress RuntimeWarning in emcee
warnings.filterwarnings("ignore", category=RuntimeWarning)

# Step 2: Upload both ZIP files at once
print("Please upload both actlite_3yr_v2p2.zip and Reference.zip")
uploaded = files.upload()

# Check if both files are uploaded
required_files = ['actlite_3yr_v2p2.zip', 'Reference.zip']
uploaded_files = list(uploaded.keys())
missing = [f for f in required_files if f not in uploaded_files]
if missing:
    raise ValueError(f"Missing files: {missing}. Please rerun and upload both.")

# Save uploaded files to disk
act_zip_path = 'actlite_3yr_v2p2.zip'
with open(act_zip_path, 'wb') as f:
    f.write(uploaded['actlite_3yr_v2p2.zip'])

ref_zip_path = 'Reference.zip'
with open(ref_zip_path, 'wb') as f:
    f.write(uploaded['Reference.zip'])

print("Uploaded files saved successfully.")

# Step 3: Extract the ZIP files
with zipfile.ZipFile(act_zip_path, 'r') as zip_ref:
    zip_ref.extractall('act_data')
print("Extracted actlite_3yr_v2p2.zip to 'act_data'")

with zipfile.ZipFile(ref_zip_path, 'r') as zip_ref:
    zip_ref.extractall('ref_data')
print("Extracted Reference.zip to 'ref_data'")

# Step 4: Search for and load CMB data
def find_file(root_dir, filename):
    for subdir, _, files in os.walk(root_dir):
        if filename in files:
            return os.path.join(subdir, filename)
    raise FileNotFoundError(f"{filename} not found in {root_dir}")

cl_dat_path = find_file('act_data', 'ACT+SPT_cl.dat')
cov_dat_path = find_file('act_data', 'ACT+SPT_cov.dat')

# Load Cl data
with open(cl_dat_path, 'r') as f:
    lines = f.readlines()
cmb_data = np.array([list(map(float, line.strip().split())) for line in lines if line.strip()])
ell_cmb = cmb_data[:, 0]
Cl_obs = cmb_data[:, 1]
Cl_err = cmb_data[:, 2]
print(f"Loaded {len(ell_cmb)} CMB Cl points.")

# Load covariance with regex
with open(cov_dat_path, 'r') as f:
    text = f.read()
float_pattern = r'[-+]?[0-9]*\.?[0-9]+(?:[eE][-+]?[0-9]+)?'
matches = re.findall(float_pattern, text)
flat_cov = np.array([float(m) for m in matches])
expected_len = len(ell_cmb) ** 2
if len(flat_cov) != expected_len:
    raise ValueError(f"Covariance data length {len(flat_cov)} != {expected_len}.")
print(f"Loaded covariance matrix with {len(flat_cov)} elements (reshaping to {len(ell_cmb)}x{len(ell_cmb)})")
cov_mat = flat_cov.reshape(len(ell_cmb), len(ell_cmb))

# Compute condition number
cond = np.linalg.cond(cov_mat)
print(f"Covariance matrix condition number: {cond:.2e}")

# Use pseudo-inverse for stability (handles high condition number)
print("Using pseudo-inverse for covariance inversion to ensure numerical stability.")
cov_inv = np.linalg.pinv(cov_mat, rcond=1e-15)

# Step 5: Load SNIa data
snia_filename = 'ES_AND_COVARPantheon%2BSH0ES.dat.txt'
snia_path = find_file('ref_data', snia_filename)

try:
    snia_df = pd.read_csv(snia_path, sep='\s+', on_bad_lines='skip', header=0, engine='python')
    z_snia = snia_df['zHD'].values
    mu_obs = snia_df['MU_SH0ES'].values
    mu_err = snia_df['MU_SH0ES_ERR_DIAG'].values
except (KeyError, pd.errors.ParserError):
    print("Header parsing failed. Switching to index-based selection with type conversion.")
    snia_df = pd.read_csv(snia_path, sep='\s+', on_bad_lines='skip', header=None, engine='python')
    z_snia = pd.to_numeric(snia_df.iloc[1:, 2], errors='coerce').values
    mu_obs = pd.to_numeric(snia_df.iloc[1:, 10], errors='coerce').values
    mu_err = pd.to_numeric(snia_df.iloc[1:, 11], errors='coerce').values

valid = ~np.isnan(z_snia) & ~np.isnan(mu_obs) & ~np.isnan(mu_err) & (mu_err > 0)
z_snia = z_snia[valid]
mu_obs = mu_obs[valid]
mu_err = mu_err[valid]
print(f"Loaded {len(z_snia)} valid SNIa points.")

# Constants
G = 6.67430e-11
hbar = 1.0545718e-34
c = 299792.458
l_p = np.sqrt(hbar * G / c**3)
pi = np.pi

# Parameters and priors (further widened for Omega_m and gamma)
priors = {
    'Omega_m': (0.05, 0.5),    # Further widened
    'h': (0.67, 0.73),
    'gamma': (0.1, 0.4),       # Further widened
    'f_a': (1e11, 1e13),
    'm_a': (1e-5, 1e-3),
    'lambda_s': (0.3, 0.7)
}
fixed = {'beta': 0.3, 'alpha': 1.5, 'theta_s': 0.01, 'ell_string': 1e4, 'Omega_Lambda': 0.7}

# CMB Model
def model_Cl(ell, theta):
    Omega_m, h, gamma, f_a, m_a, lambda_s = theta
    alpha = fixed['alpha']
    beta = fixed['beta']
    theta_s = fixed['theta_s']
    ell_string = fixed['ell_string']
    
    term1 = alpha * (ell * (ell + 1)) / (2 * pi) * Omega_m**beta * np.exp(-gamma * ell / 2500)
    term2 = (1.0 / f_a) * m_a * np.sin(ell * theta_s)**2
    term3 = lambda_s * (l_p**2 / ell**2) * np.cos(ell / ell_string)
    return term1 + term2 + term3

# SNIa Model (Vectorized for speed, with added safety)
def model_mu(z, theta):
    Omega_m, h, gamma, _, _, _ = theta
    H0 = h * 100
    Omega_L = fixed['Omega_Lambda']
    
    if len(z) == 0:
        return np.array([])
    
    z_max = np.max(z)
    z_grid = np.linspace(0, z_max, 1000)
    denom = np.sqrt(Omega_m * (1 + z_grid)**3 + Omega_L + gamma * (l_p**2) * (1 + z_grid)**(-2))
    
    if not np.all(denom > 0):
        return np.full(len(z), np.nan)  # Invalid denom
    
    integrand = 1.0 / denom
    cum_int = cumulative_trapezoid(integrand, z_grid, initial=0)
    int_func = interp1d(z_grid, cum_int, kind='linear', fill_value='extrapolate', bounds_error=False)
    int_vals = np.maximum(int_func(z), 0)  # Clip to >=0 and avoid NaN extrapolation
    
    dL = (1 + z) * (c / H0) * int_vals
    if not np.all(dL > 0):
        return np.full(len(z), np.nan)  # Invalid dL
    
    mu = 5 * np.log10(dL) + 25
    return mu

# Log-Likelihood (with safety checks)
def log_likelihood(theta):
    Cl_model = model_Cl(ell_cmb, theta)
    mu_model = model_mu(z_snia, theta)
    
    if not np.all(np.isfinite(Cl_model)) or not np.all(np.isfinite(mu_model)):
        return -np.inf
    
    diff = Cl_obs - Cl_model
    chi2_cmb = np.dot(diff, np.dot(cov_inv, diff))
    
    diff_snia = mu_obs - mu_model
    chi2_snia = np.sum((diff_snia / mu_err)**2)
    
    ll = -0.5 * (chi2_cmb + chi2_snia)
    if not np.isfinite(ll):
        return -np.inf
    return ll

# Log-Prior
def log_prior(theta):
    for i, key in enumerate(priors.keys()):
        low, high = priors[key]
        if not (low < theta[i] < high):
            return -np.inf
    return 0.0

# Log-Posterior
def log_posterior(theta):
    lp = log_prior(theta)
    if not np.isfinite(lp):
        return -np.inf
    ll = log_likelihood(theta)
    if not np.isfinite(ll):
        return -np.inf
    return lp + ll

# MCMC Setup
nwalkers = 48  # Increased
ndim = 6
nsteps = 15000  # Increased

# Initial positions
means = [0.25, 0.70, 0.24, 1e12, 1e-4, 0.5]
initial = np.array(means) + 1e-4 * np.random.randn(nwalkers, ndim)

# Run emcee
sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior)
sampler.run_mcmc(initial, nsteps, progress=True)

# Discard burn-in and flatten
samples = sampler.get_chain(discard=1000, thin=10, flat=True)

# Output: Corner plot
labels = list(priors.keys())
fig = corner.corner(samples, labels=labels, truths=means)
fig.savefig('uqgpf_posteriors_v11.pdf')  # Updated version number

# Best-fit parameters (mean)
best_theta = np.mean(samples, axis=0)
print("Best-fit parameters:", best_theta)

# Compute residuals for CMB
Cl_best = model_Cl(ell_cmb, best_theta)
residuals = (Cl_obs - Cl_best) / Cl_err
np.savetxt('residuals_v11.csv', residuals, delimiter=',')

# Plot fit to CMB data
plt.errorbar(ell_cmb, Cl_obs, yerr=Cl_err, fmt='o', label='Data')
plt.plot(ell_cmb, Cl_best, label='UQGPF v2.0 Fit')
plt.xlabel('ell')
plt.ylabel('C_l')
plt.legend()
plt.savefig('uqgpf_fit_v11.pdf')

# LaTeX Table Output
with open('latex_table_v11.tex', 'w') as f:
    f.write('\\begin{table}\n\\centering\n\\begin{tabular}{cc}\nParameter & Value \\\\ \n\\hline\n')
    for label, val in zip(labels, best_theta):
        f.write(f'{label} & {val:.4e} \\\\ \n')
    f.write('\\end{tabular}\n\\end{table}\n')

# Compute and print final chi2 values
ll = log_likelihood(best_theta)
chi2_total = -2 * ll
Cl_best = model_Cl(ell_cmb, best_theta)
diff_cmb = Cl_obs - Cl_best
chi2_cmb = np.dot(diff_cmb, np.dot(cov_inv, diff_cmb))
chi2_snia = np.sum(((mu_obs - model_mu(z_snia, best_theta)) / mu_err)**2)
dof = len(ell_cmb) + len(z_snia) - ndim
reduced_chi2 = chi2_total / dof

print(f"Final chi2 (total): {chi2_total:.2f}")
print(f"chi2 (CMB): {chi2_cmb:.2f}")
print(f"chi2 (SNIa): {chi2_snia:.2f}")
print(f"Degrees of freedom: {dof}")
print(f"Reduced chi2: {reduced_chi2:.2f}")

print("MCMC completed. Outputs generated: uqgpf_posteriors_v11.pdf, residuals_v11.csv, uqgpf_fit_v11.pdf, latex_table_v11.tex")
