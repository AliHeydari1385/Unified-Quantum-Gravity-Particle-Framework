# UQGPF v2.0 MCMC Fitting Code (Version 8.7 - Fixed RuntimeWarning and Speedup)
# Changes from v8.6:
# - Added checks in log_likelihood to return -inf if any non-finite values or non-finite ll.
# - Vectorized model_mu using grid and interpolation for speed (avoids 1701 quad calls per likelihood).
# - This should prevent NaN propagation causing the RuntimeWarning in emcee.
# - Assumes scipy is installed (for cumulative_trapezoid and interp1d).

# Step 1: Install required packages
!pip install emcee
!pip install corner

import numpy as np
import emcee
import corner
import matplotlib.pyplot as plt
import zipfile
import os
import pandas as pd
import re  # For regex parsing
from google.colab import files  # For file upload in Colab (comment out if not in Colab)
from scipy.integrate import cumulative_trapezoid
from scipy.interpolate import interp1d

# Step 2: Upload both ZIP files at once
print("Please upload both actlite_3yr_v2p2.zip and Reference.zip")
uploaded = files.upload()

# Check if both files are uploaded
required_files = ['actlite_3yr_v2p2.zip', 'Reference.zip']
uploaded_files = list(uploaded.keys())
missing = [f for f in required_files if f not in uploaded_files]
if missing:
    raise ValueError(f"Missing files: {missing}. Please rerun and upload both.")

# Save uploaded files to disk
act_zip_path = 'actlite_3yr_v2p2.zip'
with open(act_zip_path, 'wb') as f:
    f.write(uploaded['actlite_3yr_v2p2.zip'])

ref_zip_path = 'Reference.zip'
with open(ref_zip_path, 'wb') as f:
    f.write(uploaded['Reference.zip'])

print("Uploaded files saved successfully.")

# Step 3: Extract the ZIP files
with zipfile.ZipFile(act_zip_path, 'r') as zip_ref:
    zip_ref.extractall('act_data')
print("Extracted actlite_3yr_v2p2.zip to 'act_data'")

with zipfile.ZipFile(ref_zip_path, 'r') as zip_ref:
    zip_ref.extractall('ref_data')
print("Extracted Reference.zip to 'ref_data'")

# Step 4: Search for and load CMB data
def find_file(root_dir, filename):
    for subdir, _, files in os.walk(root_dir):
        if filename in files:
            return os.path.join(subdir, filename)
    raise FileNotFoundError(f"{filename} not found in {root_dir}")

cl_dat_path = find_file('act_data', 'ACT+SPT_cl.dat')
cov_dat_path = find_file('act_data', 'ACT+SPT_cov.dat')

# Load Cl data
with open(cl_dat_path, 'r') as f:
    lines = f.readlines()
cmb_data = np.array([list(map(float, line.strip().split())) for line in lines if line.strip()])
ell_cmb = cmb_data[:, 0]
Cl_obs = cmb_data[:, 1]
Cl_err = cmb_data[:, 2]
print(f"Loaded {len(ell_cmb)} CMB Cl points.")

# Load covariance with regex
with open(cov_dat_path, 'r') as f:
    text = f.read()
float_pattern = r'[-+]?[0-9]*\.?[0-9]+(?:[eE][-+]?[0-9]+)?'
matches = re.findall(float_pattern, text)
flat_cov = np.array([float(m) for m in matches])
expected_len = len(ell_cmb) ** 2
if len(flat_cov) != expected_len:
    raise ValueError(f"Covariance data length {len(flat_cov)} != {expected_len}.")
print(f"Loaded covariance matrix with {len(flat_cov)} elements (reshaping to {len(ell_cmb)}x{len(ell_cmb)})")
cov_mat = flat_cov.reshape(len(ell_cmb), len(ell_cmb))

# Compute inverse covariance
try:
    cov_inv = np.linalg.inv(cov_mat)
except np.linalg.LinAlgError:
    print("Covariance matrix not invertible. Using pseudo-inverse.")
    cov_inv = np.linalg.pinv(cov_mat)

# Step 5: Load SNIa data
snia_filename = 'ES_AND_COVARPantheon%2BSH0ES.dat.txt'
snia_path = find_file('ref_data', snia_filename)

try:
    snia_df = pd.read_csv(snia_path, sep='\s+', on_bad_lines='skip', header=0, engine='python')
    z_snia = snia_df['zHD'].values
    mu_obs = snia_df['MU_SH0ES'].values
    mu_err = snia_df['MU_SH0ES_ERR_DIAG'].values
except (KeyError, pd.errors.ParserError):
    print("Header parsing failed. Switching to index-based selection with type conversion.")
    snia_df = pd.read_csv(snia_path, sep='\s+', on_bad_lines='skip', header=None, engine='python')
    z_snia = pd.to_numeric(snia_df.iloc[1:, 2], errors='coerce').values
    mu_obs = pd.to_numeric(snia_df.iloc[1:, 10], errors='coerce').values
    mu_err = pd.to_numeric(snia_df.iloc[1:, 11], errors='coerce').values

valid = ~np.isnan(z_snia) & ~np.isnan(mu_obs) & ~np.isnan(mu_err) & (mu_err > 0)
z_snia = z_snia[valid]
mu_obs = mu_obs[valid]
mu_err = mu_err[valid]
print(f"Loaded {len(z_snia)} valid SNIa points.")

# Constants
G = 6.67430e-11
hbar = 1.0545718e-34
c = 299792.458
l_p = np.sqrt(hbar * G / c**3)
pi = np.pi

# Parameters and priors
priors = {
    'Omega_m': (0.20, 0.30),
    'h': (0.67, 0.73),
    'gamma': (0.23, 0.25),
    'f_a': (1e11, 1e13),
    'm_a': (1e-5, 1e-3),
    'lambda_s': (0.3, 0.7)
}
fixed = {'beta': 0.3, 'alpha': 1.5, 'theta_s': 0.01, 'ell_string': 1e4, 'Omega_Lambda': 0.7}

# CMB Model
def model_Cl(ell, theta):
    Omega_m, h, gamma, f_a, m_a, lambda_s = theta
    alpha = fixed['alpha']
    beta = fixed['beta']
    theta_s = fixed['theta_s']
    ell_string = fixed['ell_string']
    
    term1 = alpha * (ell * (ell + 1)) / (2 * pi) * Omega_m**beta * np.exp(-gamma * ell / 2500)
    term2 = (1.0 / f_a) * m_a * np.sin(ell * theta_s)**2
    term3 = lambda_s * (l_p**2 / ell**2) * np.cos(ell / ell_string)
    return term1 + term2 + term3

# SNIa Model (Vectorized for speed)
def model_mu(z, theta):
    Omega_m, h, gamma, _, _, _ = theta
    H0 = h * 100
    Omega_L = fixed['Omega_Lambda']
    
    if len(z) == 0:
        return np.array([])
    
    z_max = np.max(z)
    z_grid = np.linspace(0, z_max, 1000)
    denom = np.sqrt(Omega_m * (1 + z_grid)**3 + Omega_L + gamma * (l_p**2) * (1 + z_grid)**(-2))
    
    if not np.all(denom > 0):
        return np.full(len(z), np.nan)  # Invalid denom
    
    integrand = 1.0 / denom
    cum_int = cumulative_trapezoid(integrand, z_grid, initial=0)
    int_func = interp1d(z_grid, cum_int, kind='linear', fill_value='extrapolate')
    int_vals = int_func(z)
    
    dL = (1 + z) * (c / H0) * int_vals
    if not np.all(dL > 0):
        return np.full(len(z), np.nan)  # Invalid dL
    
    mu = 5 * np.log10(dL) + 25
    return mu

# Log-Likelihood (with safety checks)
def log_likelihood(theta):
    Cl_model = model_Cl(ell_cmb, theta)
    mu_model = model_mu(z_snia, theta)
    
    if not np.all(np.isfinite(Cl_model)) or not np.all(np.isfinite(mu_model)):
        return -np.inf
    
    diff = Cl_obs - Cl_model
    chi2_cmb = np.dot(diff, np.dot(cov_inv, diff))
    
    diff_snia = mu.obs - mu_model
    chi2_snia = np.sum((diff_snia / mu_err)**2)
    
    ll = -0.5 * (chi2_cmb + chi2_snia)
    if not np.isfinite(ll):
        return -np.inf
    return ll

# Log-Prior
def log_prior(theta):
    for i, key in enumerate(priors.keys()):
        low, high = priors[key]
        if not (low < theta[i] < high):
            return -np.inf
    return 0.0

# Log-Posterior
def log_posterior(theta):
    lp = log_prior(theta)
    if not np.isfinite(lp):
        return -np.inf
    ll = log_likelihood(theta)
    if not np.isfinite(ll):
        return -np.inf
    return lp + ll

# MCMC Setup
nwalkers = 32
ndim = 6
nsteps = 10000

# Initial positions
means = [0.25, 0.70, 0.24, 1e12, 1e-4, 0.5]
initial = np.array(means) + 1e-4 * np.random.randn(nwalkers, ndim)

# Run emcee
sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior)
sampler.run_mcmc(initial, nsteps, progress=True)

# Discard burn-in and flatten
samples = sampler.get_chain(discard=1000, thin=10, flat=True)

# Output: Corner plot
labels = list(priors.keys())
fig = corner.corner(samples, labels=labels, truths=means)
fig.savefig('uqgpf_posteriors_v9.pdf')

# Best-fit parameters (mean)
best_theta = np.mean(samples, axis=0)
print("Best-fit parameters:", best_theta)

# Compute residuals for CMB
Cl_best = model_Cl(ell_cmb, best_theta)
residuals = (Cl_obs - Cl_best) / Cl_err
np.savetxt('residuals_v9.csv', residuals, delimiter=',')

# Plot fit to CMB data
plt.errorbar(ell_cmb, Cl_obs, yerr=Cl_err, fmt='o', label='Data')
plt.plot(ell_cmb, Cl_best, label='UQGPF v2.0 Fit')
plt.xlabel('ell')
plt.ylabel('C_l')
plt.legend()
plt.savefig('uqgpf_fit_v9.pdf')

# LaTeX Table Output
with open('latex_table_v9.tex', 'w') as f:
    f.write('\\begin{table}\n\\centering\n\\begin{tabular}{cc}\nParameter & Value \\\\ \n\\hline\n')
    for label, val in zip(labels, best_theta):
        f.write(f'{label} & {val:.4e} \\\\ \n')
    f.write('\\end{tabular}\n\\end{table}\n')

print("MCMC completed. Outputs generated: uqgpf_posteriors_v9.pdf, residuals_v9.csv, uqgpf_fit_v9.pdf, latex_table_v9.tex")
